{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShakespeareGenerator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinSikorskiBase2S/machine-learning-intro-workshop/blob/master/ShakespeareGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJQSJha_oroD",
        "colab_type": "text"
      },
      "source": [
        "This notebook based on (originally copied from) https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "edfbxDDh2AEs"
      },
      "source": [
        "## Predict Shakespeare with Cloud TPUs and Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNo1Vfghpa8j"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example uses [tf.keras](https://www.tensorflow.org/guide/keras) to build a *language model* and train it on a Cloud TPU. This language model predicts the next character of text given the text so far. The trained model can generate new snippets of text that read in a similar style to the text training data.\n",
        "\n",
        "The model trains for 10 epochs and completes in approximately 5 minutes.\n",
        "\n",
        "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dgAHfQtuhddd"
      },
      "source": [
        "## Learning objectives\n",
        "\n",
        "In this Colab, you will learn how to:\n",
        "*   Build a two-layer, forward-LSTM model.\n",
        "*   Use distribution strategy to produce a `tf.keras` model that runs on TPU version and then use the standard Keras methods to train: `fit`, `predict`, and `evaluate`.\n",
        "*   Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QrprJD-R-410"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_I0RdnOSkNmi"
      },
      "source": [
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kYxeFuKCUx9d"
      },
      "source": [
        "TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "## Data, model, and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xzpUtDMqmA-x"
      },
      "source": [
        "In this example, you train the model on the combined works of William Shakespeare, then use the model to compose a play in the style of *The Great Bard*:\n",
        "\n",
        "<blockquote>\n",
        "Loves that led me no dumbs lack her Berjoy's face with her to-day.  \n",
        "The spirits roar'd; which shames which within his powers  \n",
        "\tWhich tied up remedies lending with occasion,  \n",
        "A loud and Lancaster, stabb'd in me  \n",
        "\tUpon my sword for ever: 'Agripo'er, his days let me free.  \n",
        "\tStop it of that word, be so: at Lear,  \n",
        "\tWhen I did profess the hour-stranger for my life,  \n",
        "\tWhen I did sink to be cried how for aught;  \n",
        "\tSome beds which seeks chaste senses prove burning;  \n",
        "But he perforces seen in her eyes so fast;  \n",
        "And _  \n",
        "</blockquote>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KRQ6Fjra3Ruq"
      },
      "source": [
        "### Download data\n",
        "\n",
        "Download *The Complete Works of William Shakespeare* as a single text file from [Project Gutenberg](https://www.gutenberg.org/). You use snippets from this file as the *training data* for the model. The *target* snippet is offset by one character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j8sIXh1DEDDd",
        "outputId": "d2769ab3-efc9-48cd-ce27-d49493211a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!wget --show-progress --continue -O /content/shakespeare.txt http://www.gutenberg.org/files/100/100-0.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-03 16:38:00--  http://www.gutenberg.org/files/100/100-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AbL6cqCl7hnt"
      },
      "source": [
        "### Build the input dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7nbGKAHi0dx",
        "colab_type": "text"
      },
      "source": [
        "We just downloaded some text. The following shows the start of the text and a random snippet so we can get a feel for the whole text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJiYai-GjQRk",
        "colab_type": "code",
        "outputId": "c2360934-c97a-4cba-a283-46a0d1c4464a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!head -n5 /content/shakespeare.txt\n",
        "!echo \"...\"\n",
        "!shuf -n5 /content/shakespeare.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿\r\n",
            "Project Gutenberg’s The Complete Works of William Shakespeare, by William\r\n",
            "Shakespeare\r\n",
            "\r\n",
            "This eBook is for the use of anyone anywhere in the United States and\r\n",
            "...\n",
            "  TITUS. Welcome, my lord; welcome, dread Queen;\n",
            "\n",
            "  _O mistress mine, where are you roaming?\n",
            "Widow Dido said you? You make me study of that; she was of Carthage,\n",
            "    To love and honour Henry as her lord.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E3V4V-Jxmuv3",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/shakespeare_with_tpu_and_keras.ipynb')\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "SHAKESPEARE_TXT = '/content/shakespeare.txt'\n",
        "\n",
        "def transform(txt):\n",
        "  return np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "\n",
        "def input_fn(seq_len=100, batch_size=1024):\n",
        "  \"\"\"Return a dataset of source and target sequences for training.\"\"\"\n",
        "  with tf.io.gfile.GFile(SHAKESPEARE_TXT, 'r') as f:\n",
        "    txt = f.read()\n",
        "\n",
        "  source = tf.constant(transform(txt), dtype=tf.int32)\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices(source).batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "  def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "  ds = ds.map(split_input_target).shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  return ds.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bbb05dNynDrQ"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "The model is defined as a two-layer, forward-LSTM, the same model should work both on CPU and TPU.\n",
        "\n",
        "Because our vocabulary size is 256, the input dimension to the Embedding layer is 256.\n",
        "\n",
        "When specifying the arguments to the LSTM, it is important to note how the stateful argument is used. When training we will make sure that `stateful=False` because we do want to reset the state of our model between batches, but when sampling (computing predictions) from a trained model, we want `stateful=True` so that the model can retain information across the current batch and generate more interesting text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLEM-fLJlEEt",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  return tf.keras.Model(inputs=[source], outputs=[predicted_char])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzBYDJI0_Tfm"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "First, we need to create a distribution strategy that can use the TPU. In this case it is TPUStrategy. You can create and compile the model inside its scope. Once that is done, future calls to the standard Keras methods `fit`, `evaluate` and `predict` use the TPU.\n",
        "\n",
        "Again note that we train with `stateful=False` because while training, we only care about one batch at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ExQ922tfzSGA",
        "outputId": "cdd019bc-f195-4862-9620-abd70fb64386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  training_model = lstm_model(seq_len=100, stateful=False)\n",
        "  training_model.compile(\n",
        "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "training_model.fit(\n",
        "    input_fn(),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=15\n",
        ")\n",
        "training_model.save_weights('/tmp/bard.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.15.243.226:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 9445113799111163467)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10524048438140420198)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10140601553991962587)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10164424811476367595)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12972909931231250802)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18116245144423567864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8768386926499530920)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14775763514280426436)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17667959361662901333)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16351914051799106915)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4107445027328872508)\n",
            "Epoch 1/15\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 3.5459 - sparse_categorical_accuracy: 0.1681\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 3.1955 - sparse_categorical_accuracy: 0.1966\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 2.7651 - sparse_categorical_accuracy: 0.2597\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.9480 - sparse_categorical_accuracy: 0.4319\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.5071 - sparse_categorical_accuracy: 0.5466\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3298 - sparse_categorical_accuracy: 0.5917\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.2659 - sparse_categorical_accuracy: 0.6074\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.2292 - sparse_categorical_accuracy: 0.6166\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.2008 - sparse_categorical_accuracy: 0.6239\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.1800 - sparse_categorical_accuracy: 0.6293\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.1576 - sparse_categorical_accuracy: 0.6357\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.1451 - sparse_categorical_accuracy: 0.6389\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.1358 - sparse_categorical_accuracy: 0.6414\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.1247 - sparse_categorical_accuracy: 0.6444\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.1155 - sparse_categorical_accuracy: 0.6468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TCBtcpZkykSf"
      },
      "source": [
        "### Make predictions with the model\n",
        "\n",
        "Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "Start the model off with a *seed* sentence, then generate 250 characters from it. The model makes five predictions from the initial seed.\n",
        "\n",
        "The predictions are done on the CPU so the batch size (5) in this case does not have to be divisible by 8.\n",
        "\n",
        "Note that when we are doing predictions or, to be more precise, text generation, we set `stateful=True` so that the model's state is kept between batches. If stateful is false, the model state is reset between each batch, and the model will only be able to use the information from the current batch (a single character) to make a prediction.\n",
        "\n",
        "The output of the model is a set of probabilities for the next character (given the input so far). To build a paragraph, we predict one character at a time and sample a character (based on the probabilities provided by the model). For example, if the input character is \"o\" and the output probabilities are \"p\" (0.65), \"t\" (0.30), others characters (0.05), then we allow our model to generate text other than just \"Ophelia\" and \"Othello.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tU7M-EGGxR3E",
        "outputId": "716b6624-6056-42c9-aa27-834b3add6dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BATCH_SIZE = 15\n",
        "PREDICT_LEN = 1000\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "\n",
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n",
        "\n",
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "  \n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(256, p=next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  \n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  generated = ''.join([chr(c) for c in p])  # Convert back to text\n",
        "  print(generated)\n",
        "  print()\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION 0\n",
            "\n",
            "\n",
            " Down,\r\n",
            "good Sir Proteus, Captain Gloucester!\r\n",
            "\r\n",
            "ANNERCHBISHOP.\r\n",
            "Take thy master from Venus your stronger, see we hangs for beauty;\r\n",
            "Nature makes thee Priam doubt:\r\n",
            "That he is here, curs, and, by my sorrow,\r\n",
            "That were by my woes, and though we wedding one)\r\n",
            "Lip this stream from heart, great\r\n",
            "Gads then comes surely; he did.\r\n",
            "Hark, you calld with thy time\r\n",
            "And seize him and hath an Arm. The ball of youth sweet Toby,\r\n",
            "Who, in the shape, and stand nor t.\r\n",
            "\r\n",
            "PRINCE.\r\n",
            "No, no: then can yours; I will not have your companion. Would I will\r\n",
            "meet for you must obey her forward; therefore\r\n",
            "my good reward, and leanger.\r\n",
            "\r\n",
            " [_Exeunt Silius, Donalban and Attendant._]\r\n",
            "\r\n",
            "For, dearly, on Parolles; O, come, Sir,\r\n",
            "Thus I that, my lord your Grace is must die;\r\n",
            "Therefore I was the joy:  Do never may ever say stand by, and please your Majesty\r\n",
            "Bear the fearful burdty innocent:\r\n",
            "She that hear you do prates his queen,\r\n",
            "The narrow vices, goodness. God wear a friend! O Jupiter.\r\n",
            "\r\n",
            "ANTIPHOLUS OF EPHESUS.\r\n",
            "Bear hi\n",
            "\n",
            "PREDICTION 1\n",
            "\n",
            "\n",
            " It fell before\r\n",
            "Through frowning broken heart, and mourner.\r\n",
            "Nothing but your sweet mald and debatation,\r\n",
            "Took the scald away a corruption on mines tend,\r\n",
            "Behind me and seek this held almost speed;\r\n",
            "Weeping, what they all at everything?\r\n",
            "I hipper, pardon me; let\r\n",
            "thrive, falcorant, brave soldiers, favour, that you may be my husband,\r\n",
            "And showd him frozen else, promise\r\n",
            "in our wills in bed, had rather, shame,\r\n",
            "Supposed frame th aid to him as this course as hates\r\n",
            "The tongue of what state marvellous head;\r\n",
            "The respect I knew now sure for thee, and now\r\n",
            "through, hearing one, courage, with his metal targets, entreaties, and come hither;\r\n",
            "Do then once all day here and swear; to prophesied,\r\n",
            "The last-beards of ours.\r\n",
            "\r\n",
            "HAMLET.\r\n",
            "[_Kneeling._] Speak, a part of the canker blood.\r\n",
            "\r\n",
            "KING.\r\n",
            "Your quanton done, this first,\r\n",
            "thattell, grant for constraight, the sovereign will\r\n",
            "And kiss do good, and murder Clenament\r\n",
            "The day and they hear our trifle,\r\n",
            "I cannot rull order,\r\n",
            "Which does, swallowd; his \n",
            "\n",
            "PREDICTION 2\n",
            "\n",
            "\n",
            " He will\r\n",
            "make degrees to their axe that man,\r\n",
            "Oerivours any sudden eyes,\r\n",
            "That way blessed stronger sores drown,\r\n",
            "A right. Bear them ours; though they freely,\r\n",
            "You have in your anchors can inform thee,\r\n",
            "By the paper, let them be new worthy villain\r\n",
            "They were an armed. Thus affright not yet an Ireland.\r\n",
            "\r\n",
            "ROSENCRANTZ.\r\n",
            "All, I think, sir; let our way what on her\r\n",
            "permission won into my demands.dong sir, in nar with the\r\n",
            "whisper.\r\n",
            "Pyright Caius, and Inlion\r\n",
            "A babe.\r\n",
            "\r\n",
            "MESSENGER.\r\n",
            "As far manly offence, which never more\r\n",
            "leave her thanks for the true known, say Falstaff\r\n",
            "Calld not the hatch.\r\n",
            "\r\n",
            "HOTSPUR.\r\n",
            "By place, or elsewhall it.\r\n",
            "\r\n",
            "FIRST LORD.\r\n",
            "That I am a daughter, created, and, good breast.\r\n",
            "\r\n",
            "FALSTAFF.\r\n",
            "How? the man that came but what others! I know\r\n",
            "Falsale, and be to see not. But how dost thou dilano?\r\n",
            "Whiles Antony?\r\n",
            "\r\n",
            "POINS.\r\n",
            "I cannot do it.\r\n",
            "\r\n",
            "PISANIO.\r\n",
            "Well praisd, come, I know neither.\r\n",
            "\r\n",
            "KATHERINA.\r\n",
            "Alas, give me thy silence,\r\n",
            "My wings and good cruelhed, and the noblest arms a\n",
            "\n",
            "PREDICTION 3\n",
            "\n",
            "\n",
            "        38 is'\r\n",
            "  cannot love thy hand; whom your promise having a corporal territor\r\n",
            "    I mean there's snow-whipped that has feasts: we\r\n",
            "    As when they damn'd the poor dance once away!\r\n",
            "    [To CIVIA]  What say you deriv'd\r\n",
            "    But for a tenought? Ephess, fair report, good friar.\r\n",
            "  THIRD CITIZEN. Leave me, sir.\r\n",
            "  ENOBARBUS. O that spirit was a paper;\r\n",
            "    And therefore, when they come in my life,\r\n",
            "    In players- for shame, sprite, but with him in.\r\n",
            "                                               [They went threes od. Up and pardon the QUEEN arm\r\n",
            "  GENTLEMAN, his man waistor,\r\n",
            "    Re-enter PRINCE OF TIMON retire,\r\n",
            "    Whence, for ever in ransom here,\r\n",
            "    And yet she is king, which are on mine.\r\n",
            "    But took him dear sir, for my dream on golden\r\n",
            "    Can know-worm and the different have; and that sorrow\r\n",
            "    Were ten ready, and speak 'ay, but then she\r\n",
            "    Confoundst thou of this.\r\n",
            "\r\n",
            "                              Enter PRINCE JOHN OF SYRACUSE\r\n",
            "  GLECUMPHREY\r\n",
            "  WOLSEY. Sir, will thi\n",
            "\n",
            "PREDICTION 4\n",
            "\n",
            "\n",
            " But yet muster,\r\n",
            "The slander, being first.\r\n",
            "\r\n",
            "PRINCE.\r\n",
            "What have I remembered.\r\n",
            "\r\n",
            " [_A friend see.I see a prize. Then he walk harbinger.\r\n",
            "\r\n",
            "HOSTESS.\r\n",
            "Is this wretched?\r\n",
            "\r\n",
            "KING.\r\n",
            "Pray you, truly, sir: hear that thou thinkest thou?\r\n",
            "\r\n",
            " [_Exeunt._]\r\n",
            "\r\n",
            "SCENE IV. SCENE IX.\r\n",
            "\r\n",
            "\r\n",
            "A present again.\r\n",
            "\r\n",
            "POLONIUS.\r\n",
            "I purpos may read the riots.\r\n",
            "\r\n",
            "HAMLET.\r\n",
            "Salery and epitaph! but from well, a peasant ravisher.\r\n",
            "\r\n",
            "FIRST LORD.\r\n",
            "I hope my fools are almost a queen. Gracious deed,\r\n",
            "Who had put your lives fordame.\r\n",
            "\r\n",
            "TRIBUNE.\r\n",
            "True. Say this, will oer-cried; but\r\n",
            "Theyll say, sure, they will;\r\n",
            "Ill enmity yet, aidement. Thou art\r\n",
            "virtue, for careless-bry, may we be revent!\r\n",
            "\r\n",
            "FALSTAFF.\r\n",
            "It would be defoald for thine own decays?\r\n",
            "Your speech shall be our people;\r\n",
            "And, had banished and lend my bonding light\r\n",
            "As true a giant sun fills their hearts.\r\n",
            "Well, Bardolph, my mind, kindness,\r\n",
            "Commit me, foolish shame, here is my glass I love;\r\n",
            "Your mistress dare painted their faces\r\n",
            "In rest shall not begrant, I wot.\n",
            "\n",
            "PREDICTION 5\n",
            "\n",
            "\n",
            " Take thou want prophesy\r\n",
            "varlet. For my wife is very\r\n",
            "well, and be\r\n",
            "Quickly fleece.\r\n",
            "\r\n",
            "GHOST.\r\n",
            "Nay, let them pleas'd\r\n",
            "For some furniturer in my\r\n",
            "fruitful. Is't not send her?\r\n",
            "\r\n",
            "PERITHOUS.\r\n",
            "Do this, Grey, I broken you merry! Bell fetch for\r\n",
            "Thy last applause thousands, see thee. Hark, have\r\n",
            "moved me well; having itself\r\n",
            "justice, and then die at stock; hence am I\r\n",
            "Says in a malice of us, adventures\r\n",
            "As your eyelids shall make her all,\r\n",
            "But this Herefords covert, save thy life\r\n",
            "Have pay me, hark, taste, what thou didst undertake\r\n",
            "Yet does presently breaks, when we talk on the righteous,\r\n",
            "Since food through again nature is safe dwell\r\n",
            "That our budder foul, here I have no conscience.\r\n",
            "\r\n",
            "BELARIUS.\r\n",
            "Pervest, tell her, Prince of France,\r\n",
            "I, for here be ourself.\r\n",
            "\r\n",
            "HAMLET.\r\n",
            "Then do you me, do not?\r\n",
            "\r\n",
            "HORATIO.\r\n",
            "Wantavia men do impress?\r\n",
            "\r\n",
            "HORATIO.\r\n",
            "This forward are not I, what by her thankfuln?\r\n",
            "\r\n",
            "DROMIO OF EPHESUS.\r\n",
            "Do you think of all the tribe,\r\n",
            "So should eat minutes, nor whether your praise\n",
            "\n",
            "PREDICTION 6\n",
            "\n",
            "\n",
            " Besides, sir,\r\n",
            "Or elsewdly night, if I could may at good,\r\n",
            "Like perfection admirging my unhappy, I pray you;\r\n",
            "Four which makes me ran grant;\r\n",
            "The pointed starved my fairer way:\r\n",
            "What thing only born\r\n",
            "Was further, a remain, and took death.\r\n",
            "\r\n",
            "CLOTEN.\r\n",
            "Yare a noble tent, upon coming with murmur. Fare\r\n",
            "Pirror, what name, I kiss\r\n",
            "then through a wave to their son: learnd, there were gomels,\r\n",
            "Cullianced with a dream the other; thou\r\n",
            "said before. And, full-white,\r\n",
            "And see singled and a desperate,\r\n",
            "Beg and then twas will full sack mercy\r\n",
            "Lotches marry her, and they have on my lips\r\n",
            "Make leave truly seald under\r\n",
            "the end, whose razed and northware\r\n",
            "Will needle whereof ancient shalt was dream of.\r\n",
            "Tush, lads, gave my orangeth fresh\r\n",
            "Than second land for thought, that gentle manner any saprel.\r\n",
            "Live and bred our wings that you princely incredulous deed\r\n",
            "Is general in gold.\r\n",
            "Ah, being governd, bid me be gone!\r\n",
            "\r\n",
            "QUEEN.\r\n",
            "Because I could find Iago; and seeming two, Paris and Antonio\r\n",
            "A pinctial a sh\n",
            "\n",
            "PREDICTION 7\n",
            "\n",
            "\n",
            " I remember, you do\r\n",
            "not, things are thine own pride. When Rome\r\n",
            "I am abusdander, violence for fine, the truest\r\n",
            "one Jack a fool, and virgin, wilt thou kill\r\n",
            "purse-fall our pits.\r\n",
            "\r\n",
            "HORATIO.\r\n",
            "Amen!\r\n",
            "\r\n",
            "PRINCE.\r\n",
            "Say, No; no, I warrant.\r\n",
            "\r\n",
            "ANTIPHOLUS OF EPHESUS.\r\n",
            "After thy death,\r\n",
            "Together with simple limbs are very crack-\r\n",
            "That way sure gratily knows\r\n",
            "By their servants lenewell I for.\r\n",
            "What shall strangely, and I'll speak with thy fault\r\n",
            "Lucilius and that, and spoil\r\n",
            "He is spend thee.\r\n",
            "\r\n",
            "KING.\r\n",
            "How?\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "ACT I\r\n",
            "\r\n",
            "ACT III. SCENE I. The same.\r\n",
            "Scene IV. Parla. Countess, Lucullu my dearest palace.\r\n",
            "\r\n",
            "[Enter Horse.\r\n",
            "\r\n",
            "WORCHUS.\r\n",
            "Thanks, Master Brook.\r\n",
            "\r\n",
            "FALSTAFF.\r\n",
            "No, marry, nay, perhaps,\r\n",
            "Or o flowers a-daine, shade, and, by thy granded arbon;\r\n",
            "Like a serplankd by scarce,\r\n",
            "Ill bury unto the ear of war; and must strike an asss\r\n",
            "A rather beauty falls.\r\n",
            "\r\n",
            "DIANA.\r\n",
            "Let not you know thus twice, and hands\r\n",
            "The corn would make hillbed frighted, and stand again,\r\n",
            "Nature when a world should scorn th\n",
            "\n",
            "PREDICTION 8\n",
            "\n",
            "\n",
            " And then they say\r\n",
            "Mine eyes. Thourt slaves, like Agamemnon,\r\n",
            "Whilst unhappy woeful marks of these kings,\r\n",
            "Whilst we can Subdura! Do you\r\n",
            "Francis hadst chargd the wars of Milan, which I from sorry\r\n",
            "To be my good current, hes's mighty zeal say\r\n",
            "Thou, end; though 'twium hath made my free.\r\n",
            "\r\n",
            "FALSTAFF.\r\n",
            "O heavenly ant please you, sir.\r\n",
            "\r\n",
            "POLONIUS.\r\n",
            "By this, the Jew in that huge season.\r\n",
            "\r\n",
            "[Exit.]\r\n",
            "\r\n",
            "SERVANT.\r\n",
            "Gentle young Antipholus of Syracuse\r\n",
            "Art thou upon pay, madam?\r\n",
            "\r\n",
            "FIRST CLOWN.\r\n",
            "Hes dead.\r\n",
            "\r\n",
            "HAMLET.\r\n",
            "O, I cannot live;\r\n",
            "I do reward me at his tomb.\r\n",
            "The reputation profounds make\r\n",
            "A revel in them, the cat;\r\n",
            "So sweetly any turn for every ordinary dwed.\r\n",
            "Your part of an hour tonight; but I know when he frailties, to us\r\n",
            "away, all neer report;\r\n",
            "Beyond in manly days;\r\n",
            "Some shiningbiest talons at hand, thine and desperate people,\r\n",
            "Leave patience that purpose may move his ring,\r\n",
            "And in him accept\r\n",
            "Delightful Valour, what hear no well-watches dead. She is fought,\r\n",
            "And sweetly dower many c\n",
            "\n",
            "PREDICTION 9\n",
            "\n",
            "\n",
            " I confess\r\n",
            "    And dream'd herselfe to wish; and so being falses-\r\n",
            "    But where lust thou liest, indeed, and be gone,\r\n",
            "    Break with terruality in expressd\r\n",
            "    As homewards legs appear,\r\n",
            "    When heav'ns for files, and necessity\r\n",
            "    That all thing.\r\n",
            "  ROSALIND. Farewell; this marches have comes much,\r\n",
            "    Or else be logged with him and stand to my hope shall see?- the Prince,\r\n",
            "    And give they wrong, and take my court\r\n",
            "    In such power or something.\r\n",
            "  IPHALLOW. What good Prince Don John!\r\n",
            "  MARCIUS. What should was an unwillinge!\r\n",
            "    Thou bear'st all the young Silvia forest o' th'\r\n",
            "    rememb'rd; more have before any; and you,\r\n",
            "    will I see you all, less than for th' story.\r\n",
            "  LEPIDUS. Have you mean that were upon the blame?\r\n",
            "  SILIUS. Let him from another.\r\n",
            "\r\n",
            "                  Enter Luciana\r\n",
            "\r\n",
            "  WARWICK. Though enral'd begins the chain:\r\n",
            "    Alas, I do approach him from falln\r\n",
            "    And purgd the oath and minister guest,\r\n",
            "    And harsh and newly mutin'd, and bring forth\r\n",
            "    \n",
            "\n",
            "PREDICTION 10\n",
            "\n",
            "\n",
            " Remaining, and\r\n",
            "    love them.\r\n",
            "  ANTONY. Thanks, for they laugh when thou hearst,\r\n",
            "    And in their servant slew\r\n",
            "    the bowl in hand, and you were chapel.\r\n",
            "  JAQUES. Why, my fair Pind-absence thy death,\r\n",
            "    I will come to be said 'twere but a custom, living first,\r\n",
            "    With all my breathing indeed\r\n",
            "    By rules must not be plant him;\r\n",
            "    Remember, urgin-crown past sail'd, and never travel, and call your shoeing's daughter to death,\r\n",
            "    It is a veren sleeping will wears; see her wills have deceived;\r\n",
            "    Which end out zeal, when, or lodge, will not surprise a pennyworth,\r\n",
            "    Which cannot break the end must be\r\n",
            "    So stray- Star the lunatic sins\r\n",
            "    Your nuptial carries a lady above\r\n",
            "    Your deep million, love my sighs; tarry, proud,\r\n",
            "    Shall veng'd up with me. From the rascal! 'tis now care for my pow'r apart\r\n",
            "    our brothers that doth bear?\r\n",
            "  ORLANDO. I speak not out on thy house.\r\n",
            "  POMPEY. No.\r\n",
            "  HOSTESS. My lord, what enemies' drum?\r\n",
            "  MARCIUS. Would I can say many ma\n",
            "\n",
            "PREDICTION 11\n",
            "\n",
            "\n",
            " Tell me once account,\r\n",
            "As I hate strange and arms,\r\n",
            "Shall begettant like a bond,\r\n",
            "And with such brands can make heaven, to my auvil.\r\n",
            "\r\n",
            "ANTIPHOLUS OF EPHESUS.\r\n",
            "Ah, Burgundy, well be\r\n",
            "Will that I am namd to do for it!\r\n",
            "\r\n",
            "PAROLLES.\r\n",
            "The beaper upon it.\r\n",
            "\r\n",
            "CLOWN.\r\n",
            "Lords, Menepare Merchant; in excellent guard again.\r\n",
            "\r\n",
            "HOTSPUR.\r\n",
            "My lord, let me say.\r\n",
            "\r\n",
            "DOUGLAS.\r\n",
            "By that a salad verse finds such knowledge:\r\n",
            "   Have us'd with patience being bought me from herself:\r\n",
            "Yet bigs compounded heart, Ill far\r\n",
            "Can it is summer, sure:\r\n",
            "Take him give ear, dispatchd nor leave and errace,\r\n",
            "O fed on Angelo, and nurse sorel. So, his banquet\r\n",
            "Is no man, I did enlark, kneel down, and while nong,\r\n",
            "With those that some hope\r\n",
            "In this well comes to save your knowledge.\r\n",
            "\r\n",
            "HORATIO.\r\n",
            "Approach and inventory remain,\r\n",
            "Thou canst cursed for thy sovereign,\r\n",
            "That I am (name out with me,\r\n",
            "And nature must retreats with\r\n",
            "A greater swuffling dart,\r\n",
            "Nearzn doth sleepffer this for mine own daffed,\r\n",
            "From fall of love with him,\n",
            "\n",
            "PREDICTION 12\n",
            "\n",
            "\n",
            " Enow how\r\n",
            "    thou art greatness! Your great vanius, my liege,\r\n",
            "    Since thou begans more woes. You are gone\r\n",
            "    Of those infering treason called;\r\n",
            "    Spulking on blood; and such a tapster,\r\n",
            "    But when I have seen before eerely,\r\n",
            "      will hold it, madam, in a ratherly serpents.\r\n",
            "    My fancy this parable key, or accus'd,\r\n",
            "    Set from heart thine cannot skill I\r\n",
            "    Have neither abhorred noble tear,\r\n",
            "    With th Rosalind golden whole\r\n",
            "  of godal revels than grows, where all\r\n",
            "    die with his men, that makes are tarred.\r\n",
            "    Then being impart of me-\r\n",
            "  MENENIUS. Thank you in good care,\r\n",
            "    Even with your sister so much, now I'll make our god\r\n",
            "    Was my sigh, and prepare her, you may say to weeping-\r\n",
            "    I shot no more upon me this.\r\n",
            "  ENOBARBUS. Sir, it was out of disgrace.\r\n",
            "    O'er my girl! you follow aught that I thank you. Farewell,\r\n",
            "    The melancholy of mine hath known. Heavens repute a hanging ones!\r\n",
            "    I had my head do crimele, for they would correct thee day;\r\n",
            "    Ou\n",
            "\n",
            "PREDICTION 13\n",
            "\n",
            "\n",
            " Mark Antony,\r\n",
            "    Prorutution manner of youth I love;\r\n",
            "    Making pain when to laugh go about him:\r\n",
            "    God knows not a torch when that subject\r\n",
            "    In Avern; an I learnd thy face further.\r\n",
            "    Wheres my son?\r\n",
            "  FALSTAFF. Shall we carried that largely ours?\r\n",
            "  LADY. I will not turn my memory.\r\n",
            "  ADAM. Whence have you done, my lord?\r\n",
            "    Herivil, three days from me in this inquire\r\n",
            "    But rapt to day.\r\n",
            "  SECTOR. Let him look to point; and in't my love does;\r\n",
            "    I not wear thee was praise again;\r\n",
            "    And break from him, neither being naught,\r\n",
            "    And will beguil'd my father beseechd,\r\n",
            "    And weak and scholar's thing.\r\n",
            "\r\n",
            "                         SCENE 8.\r\n",
            "\r\n",
            "                 youth and MENAS and CLEOPATRA, Queen to HOLOFERNES, LORD SADDAY]  A mirror, and my horse\r\n",
            "    Signily had left to aught from us herself hang'd!\r\n",
            "    Therefore. Well you consume no more than I can close it?\r\n",
            "    But, Sirry only, Gany ear that while my nature\r\n",
            "    Which, from the weep, and thy malier'd are friends to\n",
            "\n",
            "PREDICTION 14\n",
            "\n",
            "\n",
            " Grant?\r\n",
            "\r\n",
            "POSTHUMUS.\r\n",
            "O, tis in mind forsook i'lessary;\r\n",
            "Sweet fellow, on my cheeks. Good my lord, knight?\r\n",
            "They shale repent me now begins our mightiest day,\r\n",
            "But from your sorrow foresters, when thou are at\r\n",
            "Savient, and my sisterst.\r\n",
            "\r\n",
            " [_Throw up_] Go to, then, Gloucester and a rare rebels by Luciana\r\n",
            "\r\n",
            "Project Gutenberg)_] Would you understand me! Now for my father,\r\n",
            "that death like a pillow maid, in such\r\n",
            "peacere than limit out of your\r\n",
            "expectacles, heavens on the very meaner whole wars;\r\n",
            "And all order which we can be married to their frail)\r\n",
            "(had tarry my derision.\r\n",
            "\r\n",
            "ANTIPHOLUS OF EPHESUS.\r\n",
            "Who, it is a very right?\r\n",
            "\r\n",
            "PAROLLES.\r\n",
            "Never saw such a needle! One word:\r\n",
            "But, as it comes too light.\r\n",
            "\r\n",
            "LAFEW.\r\n",
            "Geld and in his mouth'd devils! A man follows\r\n",
            "Will not, they are a morning; activif\r\n",
            "The escap'd him in.\r\n",
            "\r\n",
            "PETRUCHIO.\r\n",
            "The armies of such a wenches, and none burnd\r\n",
            "A reputation.\r\n",
            "\r\n",
            "PORTIA.\r\n",
            "I pray you,\r\n",
            "I will, and shall the rest-\r\n",
            "\r\n",
            "You have sent temperately.\r\n",
            "\r\n",
            "ANTIPHOLUS O\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2a5cGsSTEBQD"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Learn about [Cloud TPUs](https://cloud.google.com/tpu/docs) that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.\n",
        "* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n",
        "\n",
        "On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured [deep learning VMs](https://cloud.google.com/deep-learning-vm/),  you will find [AutoML](https://cloud.google.com/automl/)*(beta)* for training custom models without writing code and [Cloud ML Engine](https://cloud.google.com/ml-engine/docs/) which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.\n"
      ]
    }
  ]
}